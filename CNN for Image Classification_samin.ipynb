{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8c7d3b-6692-484d-ab77-3476373537e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.5611 - loss: 1.0594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 871ms/step - accuracy: 0.5611 - loss: 1.0588 - val_accuracy: 0.5000 - val_loss: 1.3925 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 926ms/step - accuracy: 0.6087 - loss: 0.7436 - val_accuracy: 0.5150 - val_loss: 1.0247 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 1s/step - accuracy: 0.6320 - loss: 0.6611 - val_accuracy: 0.5775 - val_loss: 0.7183 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.6546 - loss: 0.6185 - val_accuracy: 0.6750 - val_loss: 0.5886 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 1s/step - accuracy: 0.6843 - loss: 0.5895 - val_accuracy: 0.6375 - val_loss: 0.6454 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 1s/step - accuracy: 0.6964 - loss: 0.5781 - val_accuracy: 0.6350 - val_loss: 0.6438 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 1s/step - accuracy: 0.6928 - loss: 0.5815 - val_accuracy: 0.7000 - val_loss: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 1s/step - accuracy: 0.7058 - loss: 0.5615 - val_accuracy: 0.7450 - val_loss: 0.5346 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 1s/step - accuracy: 0.7248 - loss: 0.5461 - val_accuracy: 0.7625 - val_loss: 0.5228 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 756ms/step - accuracy: 0.7283 - loss: 0.5308 - val_accuracy: 0.7300 - val_loss: 0.5270 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 696ms/step - accuracy: 0.7442 - loss: 0.5158 - val_accuracy: 0.6800 - val_loss: 0.5977 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 693ms/step - accuracy: 0.7310 - loss: 0.5267 - val_accuracy: 0.7150 - val_loss: 0.5659 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 682ms/step - accuracy: 0.7350 - loss: 0.5185 - val_accuracy: 0.7075 - val_loss: 0.5717 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 704ms/step - accuracy: 0.7545 - loss: 0.5005 - val_accuracy: 0.6425 - val_loss: 0.7782 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 682ms/step - accuracy: 0.7861 - loss: 0.4626 - val_accuracy: 0.8075 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 691ms/step - accuracy: 0.7872 - loss: 0.4586 - val_accuracy: 0.6875 - val_loss: 0.6483 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 682ms/step - accuracy: 0.7866 - loss: 0.4541 - val_accuracy: 0.7375 - val_loss: 0.6130 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 780ms/step - accuracy: 0.7889 - loss: 0.4521 - val_accuracy: 0.7925 - val_loss: 0.4377 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 708ms/step - accuracy: 0.7968 - loss: 0.4328 - val_accuracy: 0.7900 - val_loss: 0.4711 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 674ms/step - accuracy: 0.7868 - loss: 0.4416 - val_accuracy: 0.8125 - val_loss: 0.4413 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 684ms/step - accuracy: 0.8026 - loss: 0.4192 - val_accuracy: 0.8200 - val_loss: 0.4394 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 846ms/step - accuracy: 0.8193 - loss: 0.4035 - val_accuracy: 0.8025 - val_loss: 0.4198 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 823ms/step - accuracy: 0.8134 - loss: 0.4006 - val_accuracy: 0.7625 - val_loss: 0.4963 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 751ms/step - accuracy: 0.8122 - loss: 0.4049 - val_accuracy: 0.6775 - val_loss: 0.9403 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 782ms/step - accuracy: 0.8251 - loss: 0.3944 - val_accuracy: 0.7050 - val_loss: 0.6096 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 856ms/step - accuracy: 0.8157 - loss: 0.4013 - val_accuracy: 0.8275 - val_loss: 0.3900 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 749ms/step - accuracy: 0.8245 - loss: 0.3898 - val_accuracy: 0.8375 - val_loss: 0.3923 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 734ms/step - accuracy: 0.8192 - loss: 0.3860 - val_accuracy: 0.7125 - val_loss: 0.7093 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 784ms/step - accuracy: 0.8291 - loss: 0.3745 - val_accuracy: 0.7100 - val_loss: 0.7703 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 857ms/step - accuracy: 0.8382 - loss: 0.3583 - val_accuracy: 0.6775 - val_loss: 0.7680 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 533ms/step - accuracy: 0.8301 - loss: 0.3746 - val_accuracy: 0.8000 - val_loss: 0.5167 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 608ms/step - accuracy: 0.8441 - loss: 0.3615 - val_accuracy: 0.8200 - val_loss: 0.4122 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 588ms/step - accuracy: 0.8429 - loss: 0.3567 - val_accuracy: 0.8375 - val_loss: 0.3525 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 600ms/step - accuracy: 0.8399 - loss: 0.3513 - val_accuracy: 0.8775 - val_loss: 0.3308 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 595ms/step - accuracy: 0.8479 - loss: 0.3513 - val_accuracy: 0.8275 - val_loss: 0.4171 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 524ms/step - accuracy: 0.8523 - loss: 0.3362 - val_accuracy: 0.8150 - val_loss: 0.4059 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 520ms/step - accuracy: 0.8547 - loss: 0.3390 - val_accuracy: 0.8675 - val_loss: 0.3400 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 476ms/step - accuracy: 0.8484 - loss: 0.3355 - val_accuracy: 0.8375 - val_loss: 0.3607 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 469ms/step - accuracy: 0.8510 - loss: 0.3457 - val_accuracy: 0.8425 - val_loss: 0.3853 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 479ms/step - accuracy: 0.8554 - loss: 0.3315 - val_accuracy: 0.7775 - val_loss: 0.5068 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 519ms/step - accuracy: 0.8616 - loss: 0.3272 - val_accuracy: 0.8300 - val_loss: 0.4078 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 483ms/step - accuracy: 0.8620 - loss: 0.3231 - val_accuracy: 0.8325 - val_loss: 0.4387 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 577ms/step - accuracy: 0.8565 - loss: 0.3389 - val_accuracy: 0.8475 - val_loss: 0.3776 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 623ms/step - accuracy: 0.8633 - loss: 0.3204 - val_accuracy: 0.8325 - val_loss: 0.3813 - learning_rate: 1.2500e-04\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - accuracy: 0.8647 - loss: 0.3395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3626132309436798 - Validation Accuracy: 0.862500011920929\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Data Augmentation\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Split for training and validation\n",
    ")\n",
    "\n",
    "train_data = data_gen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = data_gen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Building the CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the Model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for Training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluating the Model\n",
    "eval_result = model.evaluate(val_data)\n",
    "print(f\"Validation Loss: {eval_result[0]} - Validation Accuracy: {eval_result[1]}\")\n",
    "\n",
    "# Saving the Model\n",
    "model.save('cnn_image_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdd95f-1e6c-4002-8fb9-f40914bb0e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
